{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([48, 48, 48])\n",
      "torch.Size([480, 7])\n",
      "torch.Size([480])\n",
      "1\n",
      "torch.Size([48, 48, 48])\n",
      "torch.Size([480, 7])\n",
      "torch.Size([480])\n",
      "2\n",
      "torch.Size([48, 48, 48])\n",
      "torch.Size([480, 7])\n",
      "torch.Size([480])\n",
      "3\n",
      "torch.Size([48, 48, 48])\n",
      "torch.Size([480, 7])\n",
      "torch.Size([480])\n",
      "4\n",
      "torch.Size([48, 48, 48])\n",
      "torch.Size([480, 7])\n",
      "torch.Size([480])\n",
      "5\n",
      "torch.Size([48, 48, 48])\n",
      "torch.Size([479, 7])\n",
      "torch.Size([479])\n"
     ]
    }
   ],
   "source": [
    "# Load processed data\n",
    "data_path = Path(\"data/processed\")\n",
    "data_files = []\n",
    "\n",
    "for dir in data_path.iterdir():\n",
    "    if dir.is_dir():\n",
    "        scene_file = dir / 'scene.npz'\n",
    "        if scene_file.exists():\n",
    "            data_files.append(scene_file)\n",
    "\n",
    "for idx in range(6):\n",
    "    print(idx)\n",
    "    scene_file = data_files[idx]\n",
    "            \n",
    "    scene_data = np.load(scene_file)\n",
    "\n",
    "    # Only use the last 7 entries in each grasp, as they are the values of the hand pose\n",
    "    grasps = scene_data[\"grasps\"][:, -7:]\n",
    "\n",
    "    # Convert to tensors\n",
    "    sdf = torch.from_numpy(scene_data[\"sdf\"])\n",
    "    grasps = torch.from_numpy(grasps)\n",
    "    scores = torch.from_numpy(scene_data[\"scores\"])\n",
    "\n",
    "    print(sdf.shape)\n",
    "    print(grasps.shape)\n",
    "    print(scores.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "# Problem: Some scenes have 480 grasps, some have 476-479\n",
    "# SOLVED by padding the scenes with random grasps from the same scene\n",
    "\n",
    "from dataset import GraspDataset\n",
    "dataset = GraspDataset(Path(\"data/processed\"))\n",
    "\n",
    "# Find out what the minimun number of grasps is\n",
    "min_grasps = min(len(scene_data[\"grasps\"]) for scene_data in dataset)\n",
    "print(min_grasps)\n",
    "\n",
    "# Find out what the maximum number of grasps is\n",
    "max_grasps = max(len(scene_data[\"grasps\"]) for scene_data in dataset)\n",
    "print(max_grasps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0: processing scenes [7, 3, 2, 8]\n",
      "Worker 1: processing scenes [5, 6, 9, 4]\n",
      "Worker 2: processing scenes [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Test worker logic in GraspBatchIterableDataset\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Simulate a dataset with N scenes\n",
    "num_scenes = 10\n",
    "scene_indices = list(range(num_scenes))\n",
    "\n",
    "# Shuffle if desired\n",
    "shuffle_scenes = True\n",
    "if shuffle_scenes:\n",
    "    random.seed(42)  # fixed seed for reproducibility\n",
    "    random.shuffle(scene_indices)\n",
    "\n",
    "# Simulate DataLoader settings\n",
    "num_workers = 3\n",
    "\n",
    "# Simulate how each worker would get a subset of scenes\n",
    "for worker_id in range(num_workers):\n",
    "    per_worker = int(math.ceil(len(scene_indices) / float(num_workers)))\n",
    "    start = worker_id * per_worker\n",
    "    end = min(start + per_worker, len(scene_indices))\n",
    "    indices_to_process = scene_indices[start:end]\n",
    "    \n",
    "    print(f\"Worker {worker_id}: processing scenes {indices_to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "游릭 Batch 0\n",
      "  SDF shape:         torch.Size([48, 48, 48])\n",
      "  Grasp batch shape: torch.Size([32, 7])\n",
      "  Score batch shape: torch.Size([32])\n",
      "  First 3 scores:     [9.375739097595215, -1.0, 13.231476783752441]\n",
      "\n",
      "游릭 Batch 1\n",
      "  SDF shape:         torch.Size([48, 48, 48])\n",
      "  Grasp batch shape: torch.Size([32, 7])\n",
      "  Score batch shape: torch.Size([32])\n",
      "  First 3 scores:     [-1.5, 3.9109270572662354, -1.5]\n",
      "\n",
      "游릭 Batch 2\n",
      "  SDF shape:         torch.Size([48, 48, 48])\n",
      "  Grasp batch shape: torch.Size([32, 7])\n",
      "  Score batch shape: torch.Size([32])\n",
      "  First 3 scores:     [-1.5, 10.475044250488281, 9.386157035827637]\n"
     ]
    }
   ],
   "source": [
    "# Test the GraspBatchIterableDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from dataset import GraspDataset, GraspBatchIterableDataset  # make sure this file is saved as dataset.py\n",
    "\n",
    "# Adjust this to your actual data folder\n",
    "data_path = Path(\"data/processed\")\n",
    "\n",
    "# Instantiate base scene dataset\n",
    "scene_dataset = GraspDataset(data_path)\n",
    "\n",
    "# Wrap in GraspBatchIterableDataset\n",
    "batch_dataset = GraspBatchIterableDataset(scene_dataset, grasp_batch_size=32)\n",
    "\n",
    "# Use DataLoader (important: batch_size=None for IterableDataset!)\n",
    "loader = DataLoader(batch_dataset, batch_size=None, num_workers=0)  # Set num_workers > 0 to test multiworker\n",
    "\n",
    "# Iterate and inspect\n",
    "for i, (sdf, grasp_batch, score_batch) in enumerate(loader):\n",
    "    print(f\"\\n游릭 Batch {i}\")\n",
    "    print(f\"  SDF shape:         {sdf.shape}\")            # (D, D, D) with D=48\n",
    "    print(f\"  Grasp batch shape: {grasp_batch.shape}\")    # (B, G_dim) with G_dim=7\n",
    "    print(f\"  Score batch shape: {score_batch.shape}\")    # (B,)\n",
    "    \n",
    "    print(f\"  First 3 scores:     {score_batch[:3].tolist()}\")\n",
    "    \n",
    "    if i >= 2:\n",
    "        break  # just preview first 3 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
