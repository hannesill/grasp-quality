{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains the following keys:\n",
      "- sdf\n",
      "- grasps\n",
      "- scores\n",
      "\n",
      "Shapes:\n",
      "sdf: torch.Size([48, 48, 48])\n",
      "grasps: torch.Size([480, 7])\n",
      "scores: torch.Size([480])\n",
      "\n",
      "Basic statistics:\n",
      "sdf:\n",
      "  Min: -0.7169\n",
      "  Max: 1.4683\n",
      "  Mean: 0.6416\n",
      "  Std: 0.2782\n",
      "\n",
      "grasps:\n",
      "  Min: -0.5236\n",
      "  Max: 1.8326\n",
      "  Mean: 0.1521\n",
      "  Std: 0.4945\n",
      "\n",
      "scores:\n",
      "  Min: -1.5000\n",
      "  Max: 8.6819\n",
      "  Mean: 1.6106\n",
      "  Std: 2.8319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import GraspDataset\n",
    "\n",
    "# Create dataset\n",
    "data_path = Path('data/processed')\n",
    "dataset = GraspDataset(data_path)\n",
    "\n",
    "# Get a single sample\n",
    "sample = dataset[0]\n",
    "\n",
    "# Print available keys\n",
    "print(\"Sample contains the following keys:\")\n",
    "for key in sample.keys():\n",
    "    print(f\"- {key}\")\n",
    "\n",
    "# Print tensor shapes and data types\n",
    "print(\"\\nShapes:\")\n",
    "for key, tensor in sample.items():\n",
    "    print(f\"{key}: {tensor.shape}\")\n",
    "\n",
    "# Basic statistics for numerical tensors\n",
    "print(\"\\nBasic statistics:\")\n",
    "for key, tensor in sample.items():\n",
    "    if torch.is_floating_point(tensor):\n",
    "        print(f\"{key}:\")\n",
    "        print(f\"  Min: {tensor.min().item():.4f}\")\n",
    "        print(f\"  Max: {tensor.max().item():.4f}\")\n",
    "        print(f\"  Mean: {tensor.mean().item():.4f}\")\n",
    "        print(f\"  Std: {tensor.std().item():.4f}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Overfitting on 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataset import GraspDataset\n",
    "from model import GQEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Initializing GQEstimator\n",
      "Input size: 48\n",
      "Flattened size: 3456\n",
      "Number of parameters: 1218977\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = GQEstimator(\n",
    "    input_size=48,\n",
    "    base_channels=16,\n",
    "    fc_dims=[256, 128, 64]\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Get a small number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "\tgrasps:  [-0.14973855018615723, -0.4954754710197449, 0.4909341335296631, -0.0407298319041729, -0.1630133092403412, 0.5009341835975647, -0.0955982506275177]\n",
      "\tscore:  0.6014598608016968\n",
      "Sample 1:\n",
      "\tgrasps:  [1.8254671096801758, 0.019515162333846092, -0.3190658390522003, 0.09756720811128616, -0.5070078372955322, 0.2509341835975647, 0.43570056557655334]\n",
      "\tscore:  -0.296999990940094\n",
      "Sample 2:\n",
      "\tgrasps:  [1.8254671096801758, 0.013246367685496807, -0.3490658402442932, 0.9402824640274048, 0.0366765633225441, 1.0318948030471802, 0.12721051275730133]\n",
      "\tscore:  -1.5\n",
      "torch.Size([7])\n",
      "torch.Size([])\n",
      "torch.Size([48, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "data_path = Path('data/processed')\n",
    "\n",
    "dataset = GraspDataset(data_path)\n",
    "\n",
    "scene = dataset[0]\n",
    "\n",
    "def get_samples(scene, num_samples):\n",
    "    # Get num_samples many unique indices\n",
    "    indices = torch.randperm(len(scene['grasps']))[:num_samples]\n",
    "    samples = []\n",
    "    for i in indices:\n",
    "        sample = {\n",
    "            'grasps': scene['grasps'][i].float().to(device),\n",
    "            'scores': scene['scores'][i].float().to(device),\n",
    "            'sdf': scene['sdf'].float().to(device)\n",
    "        }\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "samples = get_samples(scene, 10)\n",
    "\n",
    "for i, sample in enumerate(samples[:3]):\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(\"\\tgrasps: \", sample['grasps'].tolist())\n",
    "    print(\"\\tscore: \", sample['scores'].item())\n",
    "\n",
    "\n",
    "print(samples[0]['grasps'].shape)\n",
    "print(samples[0]['scores'].shape)\n",
    "print(samples[0]['sdf'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Overfit on these samples from that one scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.467961795674637, 7.464760744804517, 7.46210340638645, 7.459885980095715, 7.457702191639692, 7.455563902715221, 7.453464439790696, 7.451279206690378, 7.449333076179028, 7.447155543440021, 7.444989512069151, 7.442092266306281, 7.439235073467716, 7.436303801997565, 7.433306764136068, 7.4299659908749165, 7.426572826760821, 7.423071280587465, 7.419014762411825, 7.414272176870145, 7.409702169615775, 7.40385797204217, 7.3985545088013165, 7.392953398427926, 7.386128518930855, 7.379842883367838, 7.3708514354677845, 7.361000522777613, 7.349560379434843, 7.338317180075682, 7.3253641578019595, 7.313698591617867, 7.298248230991885, 7.282131543103605, 7.267710600048304, 7.2505417474545535, 7.234326729830355, 7.216762424074114, 7.202054835506715, 7.184714289727344, 7.1679052105479055, 7.151261020672973, 7.138387516769581, 7.124434551596641, 7.112075328547507, 7.1009881746023895, 7.090858816914261, 7.080819348990917, 7.072541110217571, 7.065455041080713, 7.059413346275687, 7.054255698248744, 7.051160905323923, 7.046784048713744, 7.043491150997579, 7.0399458267726, 7.037592014856637, 7.0362955261953175, 7.034375383052975, 7.032806875696406, 7.030959750153125, 7.02989266696386, 7.028749747760594, 7.027765608788468, 7.026705659297295, 7.026292797597125, 7.025503076217137, 7.024722828029189, 7.024093209323473, 7.023727515758947, 7.023252211860381, 7.0228083766472995, 7.022202886809827, 7.021771138563054, 7.021381678117905, 7.020975784867187, 7.020657080845558, 7.0203194992238425, 7.019888723164331, 7.019442126338253, 7.019259145537217, 7.018931019284355, 7.018562542818836, 7.018199762573931, 7.017877818827401, 7.01754032307872, 7.017257816206256, 7.01688933030673, 7.016706195178995, 7.016352118702708, 7.016033647095901, 7.015743215536349, 7.0154245374458695, 7.015143220179562, 7.014827535631594, 7.014545962806551, 7.014290903683286, 7.014040166010818, 7.013714813661591, 7.0133966204007265]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "losses = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "    for sample in samples:\n",
    "        optimizer.zero_grad()\n",
    "        sdf_features = model.encode_sdf(sample['sdf'])\n",
    "        flattened_features = torch.cat([sdf_features, sample['grasps']])\n",
    "        pred_quality = model(flattened_features)\n",
    "        loss = criterion(pred_quality, sample['scores'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(samples)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "print(losses)\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Full Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset samples: 15547, Calculated train size: 12437, Calculated val size: 3110\n",
      "Train dataset size: 100, Validation dataset size: 10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Load the dataset\n",
    "dataset = GraspDataset(data_path)\n",
    "\n",
    "# Split dataset into training and validation\n",
    "val_split = 0.2\n",
    "num_samples = len(dataset)\n",
    "train_size = int(num_samples * (1 - val_split))\n",
    "val_size = num_samples - train_size\n",
    "\n",
    "print(f\"Subset samples: {num_samples}, Calculated train size: {train_size}, Calculated val size: {val_size}\")\n",
    "\n",
    "# Shuffle indices\n",
    "random.seed(42)\n",
    "indices = list(range(num_samples))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split indices\n",
    "train_indices = indices[:100]\n",
    "val_indices = indices[-10:]\n",
    "\n",
    "# Create Subsets\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}, Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Total scenes: 15547, Train scenes: 12437, Val scenes: 3110\n",
      "Train dataset size: 100, Validation dataset size: 10\n",
      "Initializing GQEstimator\n",
      "Input size: 48\n",
      "Flattened size: 864\n",
      "Number of parameters: 46889\n",
      "\n",
      "Starting training for 100 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Training: 1500it [00:12, 118.42it/s]\n",
      "Epoch 1/100 Validation: 150it [00:03, 45.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 1428.0676, Val Loss: 2157.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Training: 1500it [00:09, 154.44it/s]\n",
      "Epoch 2/100 Validation: 150it [00:00, 382.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 1227.8335, Val Loss: 2020.9217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Training: 1500it [00:10, 149.67it/s]\n",
      "Epoch 3/100 Validation: 150it [00:00, 372.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 1002.7648, Val Loss: 2210.7131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Training: 1500it [00:09, 151.67it/s]\n",
      "Epoch 4/100 Validation: 150it [00:00, 322.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 955.6939, Val Loss: 1957.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Training: 1500it [00:09, 150.78it/s]\n",
      "Epoch 5/100 Validation: 150it [00:00, 382.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 1144.3349, Val Loss: 1930.4105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Training: 1500it [00:10, 147.35it/s]\n",
      "Epoch 6/100 Validation: 150it [00:00, 365.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 1113.9512, Val Loss: 1864.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Training: 1500it [00:10, 149.66it/s]\n",
      "Epoch 7/100 Validation: 150it [00:00, 364.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 904.2107, Val Loss: 2259.5488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 Training: 1500it [00:10, 149.81it/s]\n",
      "Epoch 8/100 Validation: 150it [00:00, 330.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 947.7450, Val Loss: 1749.8071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 Training: 243it [00:01, 141.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m score_batch \u001b[38;5;241m=\u001b[39m score_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# 1. Encode SDF\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m sdf_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_sdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# 2. Expand features for the grasp batch\u001b[39;00m\n\u001b[1;32m     80\u001b[0m expanded_sdf_features \u001b[38;5;241m=\u001b[39m sdf_features\u001b[38;5;241m.\u001b[39mexpand(GRASP_BATCH_SIZE, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/grasp-quality/model.py:64\u001b[0m, in \u001b[0;36mGQEstimator.encode_sdf\u001b[0;34m(self, sdf)\u001b[0m\n\u001b[1;32m     61\u001b[0m sdf \u001b[38;5;241m=\u001b[39m sdf\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Get features (channel_dim, D, D, D)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Flatten (channel_dim, D, D, D) -> (flattened_size,)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/adlr/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/adlr/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/adlr/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/adlr/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/adlr/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/adlr/lib/python3.10/site-packages/torch/nn/modules/conv.py:725\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/adlr/lib/python3.10/site-packages/torch/nn/modules/conv.py:720\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    710\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    719\u001b[0m     )\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from dataset import GraspDataset, GraspBatchIterableDataset\n",
    "from model import GQEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "\n",
    "# --- Configuration ---\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 100\n",
    "VAL_SPLIT = 0.2\n",
    "BASE_CHANNELS = 4\n",
    "FC_DIMS = [32, 16, 8]\n",
    "SCENE_BATCH_SIZE = 1 # Process one scene at a time. Increase if you have lots of system RAM.\n",
    "GRASP_BATCH_SIZE = 480 # Process all 480 grasps per scene at once. Reduce if you run out of VRAM.\n",
    "NUM_WORKERS = 4\n",
    "GRASP_BATCH_SIZE = 32\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Dataset and Dataloaders ---\n",
    "data_path = Path('data/processed')\n",
    "dataset = GraspDataset(data_path)\n",
    "\n",
    "num_samples = len(dataset)\n",
    "train_size = int(num_samples * (1 - VAL_SPLIT))\n",
    "val_size = num_samples - train_size\n",
    "print(f\"Total scenes: {num_samples}, Train scenes: {train_size}, Val scenes: {val_size}\")\n",
    "\n",
    "indices = list(range(num_samples))\n",
    "random.seed(42)\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:100]\n",
    "val_indices = indices[-10:]\n",
    "\n",
    "train_set = Subset(dataset, train_indices)\n",
    "val_set = Subset(dataset, val_indices)\n",
    "print(f\"Train dataset size: {len(train_set)}, Validation dataset size: {len(val_set)}\")\n",
    "\n",
    "# Create the iterable datasets\n",
    "train_grasp_dataset = GraspBatchIterableDataset(train_set, grasp_batch_size=GRASP_BATCH_SIZE, shuffle_scenes=True)\n",
    "val_grasp_dataset = GraspBatchIterableDataset(val_set, grasp_batch_size=GRASP_BATCH_SIZE, shuffle_scenes=False)\n",
    "\n",
    "# The dataloader now yields your desired batches directly!\n",
    "# batch_size=None is important for iterable datasets that do their own batching.\n",
    "pin_memory = torch.cuda.is_available()\n",
    "train_loader = DataLoader(train_grasp_dataset, batch_size=None, num_workers=NUM_WORKERS, pin_memory=pin_memory, persistent_workers=True)\n",
    "val_loader = DataLoader(val_grasp_dataset, batch_size=None, num_workers=NUM_WORKERS, pin_memory=pin_memory, persistent_workers=True)\n",
    "\n",
    "# --- Model, Optimizer, Loss ---\n",
    "model = GQEstimator(input_size=48, base_channels=BASE_CHANNELS, fc_dims=FC_DIMS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(f\"\\nStarting training for {EPOCHS} epochs...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    num_steps = 0\n",
    "\n",
    "    for sdf, grasp_batch, score_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Training\"):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move to device\n",
    "        sdf = sdf.to(device)\n",
    "        grasp_batch = grasp_batch.to(device)\n",
    "        score_batch = score_batch.to(device)\n",
    "\n",
    "        # 1. Encode SDF\n",
    "        sdf_features = model.encode_sdf(sdf)\n",
    "\n",
    "        # 2. Expand features for the grasp batch\n",
    "        expanded_sdf_features = sdf_features.expand(GRASP_BATCH_SIZE, -1)\n",
    "\n",
    "        # 3. Concatenate features\n",
    "        flattened_features = torch.cat([expanded_sdf_features, grasp_batch], dim=1)\n",
    "\n",
    "        # 4. Predict grasp quality and compute loss\n",
    "        pred_quality = model(flattened_features)\n",
    "        loss = criterion(pred_quality, score_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * GRASP_BATCH_SIZE\n",
    "        num_steps += GRASP_BATCH_SIZE\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_steps\n",
    "\n",
    "    # --- Validation Loop ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    num_steps = 0\n",
    "    with torch.no_grad():\n",
    "        for sdf, grasp_batch, score_batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Validation\"):\n",
    "            # Move to device\n",
    "            sdf = sdf.to(device)\n",
    "            grasp_batch = grasp_batch.to(device)\n",
    "            score_batch = score_batch.to(device)\n",
    "\n",
    "            # 1. Encode SDF\n",
    "            sdf_features = model.encode_sdf(sdf)\n",
    "\n",
    "            # 2. Expand features for the grasp batch\n",
    "            expanded_sdf_features = sdf_features.expand(GRASP_BATCH_SIZE, -1)\n",
    "\n",
    "            # 3. Concatenate features\n",
    "            flattened_features = torch.cat([expanded_sdf_features, grasp_batch], dim=1)\n",
    "\n",
    "            # 4. Predict grasp quality and compute loss\n",
    "            pred_quality = model(flattened_features)\n",
    "            loss = criterion(pred_quality, score_batch)\n",
    "\n",
    "            total_val_loss += loss.item() * GRASP_BATCH_SIZE\n",
    "            num_steps += GRASP_BATCH_SIZE\n",
    "\n",
    "\n",
    "    avg_val_loss = total_val_loss / num_steps\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "# --- Save Model ---\n",
    "model_path = \"model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved successfully to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
