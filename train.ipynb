{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains the following keys:\n",
      "- sdf\n",
      "- grasp\n",
      "- score\n",
      "- scene_idx\n",
      "- grasp_idx\n",
      "\n",
      "Shapes:\n",
      "sdf: torch.Size([48, 48, 48])\n",
      "grasp: torch.Size([19])\n",
      "score: torch.Size([])\n",
      "\n",
      "Basic statistics:\n",
      "sdf:\n",
      "  Min: -0.7169\n",
      "  Max: 1.4683\n",
      "  Mean: 0.6416\n",
      "  Std: 0.2782\n",
      "\n",
      "grasp:\n",
      "  Min: -0.2937\n",
      "  Max: 1.8255\n",
      "  Mean: 0.3404\n",
      "  Std: 0.5473\n",
      "\n",
      "Score: 0.33304598927497864\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from dataset import GraspDataset\n",
    "\n",
    "# Create dataset\n",
    "data_path = Path('data/processed')\n",
    "dataset = GraspDataset(data_path)\n",
    "\n",
    "# Get a single sample\n",
    "sample = dataset[1]\n",
    "\n",
    "# Print available keys\n",
    "print(\"Sample contains the following keys:\")\n",
    "for key in sample.keys():\n",
    "    print(f\"- {key}\")\n",
    "\n",
    "# Print tensor shapes and data types\n",
    "print(\"\\nShapes:\")\n",
    "for key, tensor in sample.items():\n",
    "    if key == \"scene_idx\" or key == \"grasp_idx\":\n",
    "        continue\n",
    "    print(f\"{key}: {tensor.shape}\")\n",
    "\n",
    "# Basic statistics for numerical tensors\n",
    "print(\"\\nBasic statistics:\")\n",
    "for key, tensor in sample.items():\n",
    "    if key == \"scene_idx\" or key == \"grasp_idx\" or key == \"score\":\n",
    "        continue\n",
    "    if torch.is_floating_point(tensor):\n",
    "        print(f\"{key}:\")\n",
    "        print(f\"  Min: {tensor.min().item():.4f}\")\n",
    "        print(f\"  Max: {tensor.max().item():.4f}\")\n",
    "        print(f\"  Mean: {tensor.mean().item():.4f}\")\n",
    "        print(f\"  Std: {tensor.std().item():.4f}\")\n",
    "        print()\n",
    "\n",
    "print(f\"Score: {sample['score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Overfitting on 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataset import GraspDataset\n",
    "from model import GQEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Initializing GQEstimator\n",
      "Input size: 48\n",
      "Flattened size: 3456\n",
      "Number of parameters: 1222049\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = GQEstimator(\n",
    "    input_size=48,\n",
    "    base_channels=16,\n",
    "    fc_dims=[256, 128, 64]\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Get a small number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset):  7462560\n",
      "Scene indices:  tensor([6212245, 4311537, 3622143,  954672, 4047315, 1407584, 5145161, 3381037,\n",
      "          75766, 5979714])\n",
      "Sample 0:\n",
      "\tgrasp:  [0.06408321857452393, 0.014916861429810524, 0.2829621136188507, 0.9840953946113586, -0.036999788135290146, -0.16905753314495087, 0.0400857999920845, -0.03852662816643715, -0.14906585216522217, 0.33989545702934265, -0.2187262624502182, -0.03906584903597832, 0.249733105301857, -0.23981529474258423, 0.0009341436671093106, 0.2580556869506836, -0.3212704062461853, 0.16093413531780243, 0.16526134312152863]\n",
      "\tscore:  1.4937500953674316\n",
      "Sample 1:\n",
      "\tgrasp:  [-0.03293197602033615, -0.019420089200139046, 0.2871796488761902, -0.21385937929153442, 0.9675678014755249, 0.01678565703332424, 0.1333979368209839, 0.306367427110672, -0.10906585305929184, 0.3082764446735382, -0.26800212264060974, 0.0909341499209404, 0.24546706676483154, -0.519659698009491, 0.020934155210852623, 0.28546708822250366, -0.3938348889350891, 0.22093413770198822, 0.0335390605032444]\n",
      "\tscore:  10.743685722351074\n",
      "Sample 2:\n",
      "\tgrasp:  [-0.05471457913517952, 0.026803359389305115, 0.2693283259868622, 0.38959622383117676, 0.8751334547996521, 0.007780775427818298, 0.2868722081184387, 0.262468159198761, 0.45093417167663574, 0.10426421463489532, 0.18972429633140564, 0.4309341311454773, 0.13377156853675842, -0.42824140191078186, 0.5109341740608215, 0.1911604106426239, -0.46419259905815125, -0.32906585931777954, 0.21927285194396973]\n",
      "\tscore:  1.9273138046264648\n",
      "torch.Size([19])\n",
      "torch.Size([])\n",
      "torch.Size([48, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "data_path = Path('data/processed')\n",
    "\n",
    "dataset = GraspDataset(data_path)\n",
    "print(\"len(dataset): \", len(dataset))\n",
    "\n",
    "def get_samples(dataset, num_samples):\n",
    "    # Get num_samples many unique indices\n",
    "    indices = torch.randperm(len(dataset))[:num_samples]\n",
    "    samples = []\n",
    "    print(\"Scene indices: \", indices)\n",
    "    for i in indices:\n",
    "        # Choose random grasp from scene\n",
    "        sample = dataset[i]\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "samples = get_samples(dataset, 10)\n",
    "\n",
    "for i, sample in enumerate(samples[:3]):\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(\"\\tgrasp: \", sample['grasp'].tolist())\n",
    "    print(\"\\tscore: \", sample['score'].item())\n",
    "\n",
    "\n",
    "print(samples[0]['grasp'].shape)\n",
    "print(samples[0]['score'].shape)\n",
    "print(samples[0]['sdf'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Overfit on these samples from that one scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.852535003143565, 33.82564838450344, 33.80239131335111, 33.78054148642987, 33.755153924250045, 33.72462977670948, 33.6906148870592, 33.65138012394309, 33.60318425199948, 33.54404980414547, 33.46539399898611, 33.37431283313781, 33.26452881507576, 33.127338499575856, 32.9278526108712, 32.66041946709156, 32.302463410794736, 31.83510336726904, 31.258318695425988, 30.54397416114807, 29.713161358237265, 28.80234619230032, 27.858371981047092, 26.954981437139214, 26.147606919333338, 25.47512131119147, 24.959192992560567, 24.57851778450422, 24.318386101722716, 24.14395805373788, 24.024524487555027, 23.943235252797603, 23.88658289909363, 23.845990458130835, 23.815415593981744, 23.791451600193977, 23.772195053100585, 23.756141915917397, 23.742214417457582, 23.727302134037018, 23.718454712629317, 23.70919724702835, 23.700012734532358, 23.690501090884208, 23.68138506114483, 23.672595292329788, 23.664178279042243, 23.655999186635018, 23.648153099417687, 23.640522351861, 23.63311766088009, 23.625816628336906, 23.61864451766014, 23.6115915030241, 23.60461548268795, 23.59764401614666, 23.59079334139824, 23.584006464481355, 23.57727320790291, 23.569409760832787, 23.563671559095383, 23.557531678676604, 23.551174625754356, 23.54473424255848, 23.538275253772735, 23.53186156153679, 23.525455075502396, 23.519081643223764, 23.51278002858162, 23.506238111853598, 23.4997787296772, 23.493344041705132, 23.486905586719512, 23.480509856343268, 23.474142563343047, 23.4677486628294, 23.461361464858054, 23.45496037900448, 23.448481079936027, 23.44202152490616, 23.43552936017513, 23.428998574614525, 23.4224096596241, 23.41585484445095, 23.409345412254332, 23.40259819626808, 23.39585976600647, 23.389098569750786, 23.382248163223267, 23.375265702605247, 23.36833682358265, 23.36142166554928, 23.354361733794214, 23.347314950823783, 23.34018041789532, 23.332942229509353, 23.32569510936737, 23.31864089667797, 23.311292245984077, 23.3039093375206]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Play around with the learning rate and run this cell multiple times \n",
    "# to see how it affects the loss curve\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    epoch_loss = 0.0\n",
    "    for sample in samples:\n",
    "        optimizer.zero_grad()\n",
    "        sdf_features = model.encode_sdf(sample['sdf'])\n",
    "        flattened_features = torch.cat([sdf_features, sample['grasp']])\n",
    "        pred_quality = model(flattened_features).squeeze()\n",
    "        loss = criterion(pred_quality, sample['score'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(samples)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "print(losses)\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Full Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset samples: 7462560, Calculated train size: 5970048, Calculated val size: 1492512\n",
      "Train dataset size: 1000, Validation dataset size: 100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Load the dataset\n",
    "dataset = GraspDataset(data_path)\n",
    "\n",
    "# Split dataset into training and validation\n",
    "val_split = 0.2\n",
    "num_samples = len(dataset)\n",
    "train_size = int(num_samples * (1 - val_split))\n",
    "val_size = num_samples - train_size\n",
    "\n",
    "print(f\"Subset samples: {num_samples}, Calculated train size: {train_size}, Calculated val size: {val_size}\")\n",
    "\n",
    "# Shuffle indices\n",
    "random.seed(42)\n",
    "indices = list(range(num_samples))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split indices\n",
    "train_indices = indices[:1000]\n",
    "val_indices = indices[-100:]\n",
    "\n",
    "# Create Subsets\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}, Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Total scenes: 7462560, Train scenes: 5970048, Val scenes: 1492512\n",
      "Train dataset size: 5000, Validation dataset size: 1000\n",
      "\n",
      "=== Data Distribution Analysis ===\n",
      "Train scores - Mean: 5.050, Std: 6.959\n",
      "Val scores   - Mean: 5.118, Std: 7.064\n",
      "Distribution difference: 0.068\n",
      "Initializing GQEstimator\n",
      "Input size: 48\n",
      "Flattened size: 864\n",
      "Number of parameters: 46873\n",
      "\n",
      "Starting training for 100 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Training: 100%|██████████| 157/157 [00:47<00:00,  3.31it/s]\n",
      "Epoch 1/100 Validation: 100%|██████████| 32/32 [00:06<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 50.1658, Val Loss: 48.2879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.57it/s]\n",
      "Epoch 2/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 42.7466, Val Loss: 42.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.55it/s]\n",
      "Epoch 3/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 38.3407, Val Loss: 38.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.59it/s]\n",
      "Epoch 4/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 36.9187, Val Loss: 37.4240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.57it/s]\n",
      "Epoch 5/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 35.7061, Val Loss: 36.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.56it/s]\n",
      "Epoch 6/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 34.3336, Val Loss: 35.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.54it/s]\n",
      "Epoch 7/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 33.1086, Val Loss: 34.5169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.50it/s]\n",
      "Epoch 8/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 31.7449, Val Loss: 33.6585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.57it/s]\n",
      "Epoch 9/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 30.5637, Val Loss: 32.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.51it/s]\n",
      "Epoch 10/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 29.4651, Val Loss: 31.5068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.49it/s]\n",
      "Epoch 11/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 28.4583, Val Loss: 30.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.50it/s]\n",
      "Epoch 12/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss: 27.5832, Val Loss: 30.1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.56it/s]\n",
      "Epoch 13/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss: 26.9205, Val Loss: 29.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.57it/s]\n",
      "Epoch 14/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Train Loss: 26.3757, Val Loss: 29.2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.56it/s]\n",
      "Epoch 15/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Train Loss: 26.0673, Val Loss: 29.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.54it/s]\n",
      "Epoch 16/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Train Loss: 25.5831, Val Loss: 28.7085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.61it/s]\n",
      "Epoch 17/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Train Loss: 25.2546, Val Loss: 28.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.60it/s]\n",
      "Epoch 18/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Train Loss: 24.9121, Val Loss: 28.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.57it/s]\n",
      "Epoch 19/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Train Loss: 24.6178, Val Loss: 28.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 Training: 100%|██████████| 157/157 [00:43<00:00,  3.58it/s]\n",
      "Epoch 20/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Train Loss: 24.3109, Val Loss: 27.8857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 Training: 100%|██████████| 157/157 [00:44<00:00,  3.51it/s]\n",
      "Epoch 21/100 Validation: 100%|██████████| 32/32 [00:04<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Train Loss: 23.4269, Val Loss: 27.8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 Training:  24%|██▍       | 38/157 [00:10<00:33,  3.54it/s]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from dataset import GraspDataset\n",
    "from model import GQEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "\n",
    "# --- Configuration ---\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "VAL_SPLIT = 0.2\n",
    "BASE_CHANNELS = 4\n",
    "FC_DIMS = [32, 8]\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Dataset and Dataloaders ---\n",
    "data_path = Path('data/processed')\n",
    "dataset = GraspDataset(data_path)\n",
    "\n",
    "num_samples = len(dataset)\n",
    "train_size = int(num_samples * (1 - VAL_SPLIT))\n",
    "val_size = num_samples - train_size\n",
    "print(f\"Total scenes: {num_samples}, Train scenes: {train_size}, Val scenes: {val_size}\")\n",
    "\n",
    "indices = list(range(num_samples))\n",
    "random.seed(42)\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:5000]\n",
    "val_indices = indices[-1000:]\n",
    "\n",
    "train_set = Subset(dataset, train_indices)\n",
    "val_set = Subset(dataset, val_indices)\n",
    "print(f\"Train dataset size: {len(train_set)}, Validation dataset size: {len(val_set)}\")\n",
    "\n",
    "# The dataloader now yields your desired batches directly!\n",
    "# batch_size=None is important for iterable datasets that do their own batching.\n",
    "pin_memory = torch.cuda.is_available()\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=pin_memory, persistent_workers=True)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=pin_memory, persistent_workers=True)\n",
    "\n",
    "# Check data distribution:\n",
    "print(\"\\n=== Data Distribution Analysis ===\")\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    train_scores.append(train_set[i]['score'].item())\n",
    "    \n",
    "for i in range(len(val_set)):\n",
    "    val_scores.append(val_set[i]['score'].item())\n",
    "\n",
    "train_scores = np.array(train_scores)\n",
    "val_scores = np.array(val_scores)\n",
    "\n",
    "print(f\"Train scores - Mean: {train_scores.mean():.3f}, Std: {train_scores.std():.3f}\")\n",
    "print(f\"Val scores   - Mean: {val_scores.mean():.3f}, Std: {val_scores.std():.3f}\")\n",
    "print(f\"Distribution difference: {abs(train_scores.mean() - val_scores.mean()):.3f}\")\n",
    "\n",
    "# --- Model, Optimizer, Loss ---\n",
    "model = GQEstimator(input_size=48, base_channels=BASE_CHANNELS, fc_dims=FC_DIMS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(f\"\\nStarting training for {EPOCHS} epochs...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    num_steps = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Training\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move to device\n",
    "        sdf_batch = batch['sdf'].to(device)\n",
    "        grasp_batch = batch['grasp'].to(device)\n",
    "        score_batch = batch['score'].to(device)\n",
    "\n",
    "        # Get the actual batch size (handles variable batch sizes)\n",
    "        actual_batch_size = sdf_batch.size(0)\n",
    "\n",
    "        # 1. Encode SDF\n",
    "        sdf_features = model.encode_sdf(sdf_batch)\n",
    "\n",
    "        # 2. No need to expand - sdf_features is already (B, flattened_size)\n",
    "        # 3. Concatenate features\n",
    "        flattened_features = torch.cat([sdf_features, grasp_batch], dim=1)\n",
    "\n",
    "        # 4. Predict grasp quality and compute loss\n",
    "        pred_quality = model(flattened_features)\n",
    "        loss = criterion(pred_quality, score_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * actual_batch_size\n",
    "        num_steps += actual_batch_size\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_steps\n",
    "\n",
    "    # --- Validation Loop ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    num_steps = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Validation\"):\n",
    "            sdf_batch = batch['sdf'].to(device)\n",
    "            grasp_batch = batch['grasp'].to(device)\n",
    "            score_batch = batch['score'].to(device)\n",
    "\n",
    "            # Get the actual batch size (handles variable batch sizes)\n",
    "            actual_batch_size = sdf_batch.size(0)\n",
    "\n",
    "            # 1. Encode SDF\n",
    "            sdf_features = model.encode_sdf(sdf_batch)\n",
    "\n",
    "            # 2. No need to expand - sdf_features is already (B, flattened_size)\n",
    "            # 3. Concatenate features\n",
    "            flattened_features = torch.cat([sdf_features, grasp_batch], dim=1)\n",
    "\n",
    "            # 4. Predict grasp quality and compute loss\n",
    "            pred_quality = model(flattened_features)\n",
    "            loss = criterion(pred_quality, score_batch)\n",
    "\n",
    "            total_val_loss += loss.item() * actual_batch_size\n",
    "            num_steps += actual_batch_size\n",
    "\n",
    "    avg_val_loss = total_val_loss / num_steps\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "# --- Save Model ---\n",
    "model_path = \"model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved successfully to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
